{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ PacerKit Quickstart\n",
        "\n",
        "**PACER: Permutation-Aligned Consensus Expert Routing**\n",
        "\n",
        "This notebook demonstrates how to use PacerKit to merge multiple models using the PACER framework.\n",
        "\n",
        "## Overview\n",
        "\n",
        "PACER is a base-free, interference-aware model merging framework that:\n",
        "1. **Aligns models geometrically** using Git Re-Basin\n",
        "2. **Computes a Consensus Barycenter** as a synthetic base\n",
        "3. **Analyzes interference** per layer\n",
        "4. **Merges low-interference layers** using DARE-TIES\n",
        "5. **Upcycles high-interference layers** to Mixture-of-Experts\n",
        "6. **Uploads to HuggingFace Hub** (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "First, install PacerKit and its dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PacerKit (run from repo root)\n",
        "# !pip install -e .\n",
        "\n",
        "# Or install dependencies directly\n",
        "# !pip install torch transformers safetensors accelerate huggingface_hub scipy scikit-learn pyyaml tqdm click\n",
        "\n",
        "# Add project root to path for local development\n",
        "import sys\n",
        "import os\n",
        "if os.path.abspath('..') not in sys.path:\n",
        "    sys.path.append(os.path.abspath('..'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Start: Merge Two Qwen Coder Models\n",
        "\n",
        "Let's merge the two 4B Qwen coding models specified in the config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pacerkit import PACERMerger\n",
        "\n",
        "# Initialize with model paths\n",
        "merger = PACERMerger([\n",
        "    \"fluently/FluentlyQwen3-Coder-4B-0909\",\n",
        "    \"SamuelBang/AesCoder-4B\"\n",
        "])\n",
        "\n",
        "# Run the full merge pipeline\n",
        "# Note: This requires GPU and will download ~8GB of models\n",
        "# merged_model = merger.merge(\n",
        "#     interference_threshold=0.35,\n",
        "#     output_path=\"./merged_qwen_coder\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using Configuration Files\n",
        "\n",
        "For reproducible merges, use YAML config files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pacerkit import PACERMerger, load_config\n",
        "\n",
        "# Load from config file\n",
        "config = load_config(\"../configs/qwen_coder_merge.yaml\")\n",
        "\n",
        "print(f\"Project: {config.project_name}\")\n",
        "print(f\"Models: {config.models}\")\n",
        "print(f\"Interference threshold: {config.pacer.interference_threshold}\")\n",
        "print(f\"Push to Hub: {config.output.push_to_hub}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize merger with config\n",
        "merger = PACERMerger(config=config)\n",
        "\n",
        "# Load models (this will download them if not cached)\n",
        "# models = merger.load_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step-by-Step Pipeline\n",
        "\n",
        "Let's walk through each phase of the PACER pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 1: Load and Validate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models\n",
        "# models = merger.load_models()\n",
        "\n",
        "# Check architecture compatibility\n",
        "# from pacerkit.utils import get_model_architecture_info\n",
        "# info = get_model_architecture_info(models[0])\n",
        "# print(f\"Architecture: {info['architecture']}\")\n",
        "# print(f\"Parameters: {info['total_parameters']:,}\")\n",
        "# print(f\"Hidden size: {info['hidden_size']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 2: Geometric Alignment (Git Re-Basin)\n",
        "\n",
        "This step aligns the permutation symmetries of all models to a common anchor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Align models (requires loaded models)\n",
        "# aligned_models = merger.align()\n",
        "\n",
        "# Check alignment quality\n",
        "# for i in range(len(aligned_models) - 1):\n",
        "#     quality = merger.aligner.compute_alignment_quality(i)\n",
        "#     print(f\"Model {i+1} alignment quality: {quality:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 3: Consensus Barycenter\n",
        "\n",
        "Compute the Fr√©chet Mean of aligned models as our synthetic base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute consensus\n",
        "# consensus_model = merger.compute_consensus()\n",
        "\n",
        "# Get deviation statistics\n",
        "# stats = merger.consensus_engine.compute_deviation_statistics()\n",
        "# print(f\"Number of parameters: {len(stats)}\")\n",
        "\n",
        "# Show top deviating layers\n",
        "# sorted_stats = sorted(stats.items(), key=lambda x: x[1]['mean_deviation_norm'], reverse=True)\n",
        "# print(\"\\nTop 5 deviating layers:\")\n",
        "# for name, stat in sorted_stats[:5]:\n",
        "#     print(f\"  {name}: {stat['mean_deviation_norm']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 4: Interference Analysis\n",
        "\n",
        "Analyze which layers have high interference (should become MoE) vs low interference (should merge)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze interference\n",
        "# report = merger.analyze_interference()\n",
        "\n",
        "# Print high-interference layers\n",
        "# high_interference = merger.interference_analyzer.get_high_interference_layers(10)\n",
        "# print(\"Top 10 high-interference layers:\")\n",
        "# for layer, score in high_interference:\n",
        "#     print(f\"  {layer}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 5: Build Merged Model\n",
        "\n",
        "Now run the full merge to create the final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run full merge (combines all phases)\n",
        "# merged_model = merger.merge(\n",
        "#     interference_threshold=0.35,\n",
        "#     top_k_experts=2,\n",
        "#     output_path=\"./merged_model\"\n",
        "# )\n",
        "\n",
        "# Get summary\n",
        "# summary = merger.interference_analyzer.get_summary()\n",
        "# print(f\"Merged layers: {summary['merge_layers']}\")\n",
        "# print(f\"MoE layers: {summary['moe_layers']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåê Upload to HuggingFace Hub\n",
        "\n",
        "PacerKit can automatically upload your merged model to HuggingFace Hub with an auto-generated model card."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, login to HuggingFace (if not already logged in)\n",
        "# from huggingface_hub import login\n",
        "# login()  # This will prompt for your token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Upload during merge\n",
        "# merged_model = merger.merge(\n",
        "#     output_path=\"./merged_qwen_coder\",\n",
        "#     push_to_hub=True,\n",
        "#     hub_repo=\"your-username/merged-qwen-coder\",\n",
        "#     private=False  # Set to True for private repo\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 2: Upload after merging\n",
        "# from pacerkit.utils import push_to_huggingface_hub\n",
        "\n",
        "# hub_url = push_to_huggingface_hub(\n",
        "#     model=merged_model,\n",
        "#     repo_id=\"your-username/merged-qwen-coder\",\n",
        "#     model_path=\"./merged_qwen_coder\",  # Local path with files\n",
        "#     private=False,\n",
        "#     commit_message=\"Upload PACER merged Qwen coder models\"\n",
        "# )\n",
        "# print(f\"Model uploaded to: {hub_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Auto-Generated Model Card\n",
        "\n",
        "PacerKit automatically generates a model card with merge details:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the generated model card\n",
        "# with open(\"./merged_qwen_coder/README.md\", \"r\") as f:\n",
        "#     print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Understanding the Interference Metric\n",
        "\n",
        "The interference metric measures how much deviation vectors conflict:\n",
        "\n",
        "$$\\mathcal{I} = 1 - \\frac{||\\sum \\Delta_k||_2}{\\sum ||\\Delta_k||_2}$$\n",
        "\n",
        "- **I ‚âà 0**: Deviations are aligned ‚Üí Safe to merge\n",
        "- **I ‚âà 1**: Deviations conflict ‚Üí Need MoE to preserve both"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from pacerkit.core.interference import InterferenceAnalyzer\n",
        "\n",
        "# Example: compute interference for synthetic data\n",
        "analyzer = InterferenceAnalyzer(threshold=0.35)\n",
        "\n",
        "# Case 1: Aligned deviations (low interference)\n",
        "aligned_devs = torch.tensor([\n",
        "    [1.0, 2.0, 3.0],\n",
        "    [1.1, 2.1, 3.1],  # Similar direction\n",
        "])\n",
        "print(f\"Aligned interference: {analyzer.compute_interference(aligned_devs):.4f}\")\n",
        "\n",
        "# Case 2: Conflicting deviations (high interference)\n",
        "conflicting_devs = torch.tensor([\n",
        "    [1.0, 0.0, 0.0],\n",
        "    [-1.0, 0.0, 0.0],  # Opposite direction\n",
        "])\n",
        "print(f\"Conflicting interference: {analyzer.compute_interference(conflicting_devs):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Zero-Shot Routing\n",
        "\n",
        "PACER uses a data-free router based on Subspace Projection Affinity:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from pacerkit.core.moe import ZeroShotRouter\n",
        "\n",
        "# Create synthetic expert deviations\n",
        "# Shape: (num_experts, d_out, d_in)\n",
        "expert_deviations = torch.randn(3, 64, 128)  # 3 experts\n",
        "\n",
        "# Initialize router\n",
        "router = ZeroShotRouter(expert_deviations, top_k=2)\n",
        "\n",
        "# Route some inputs\n",
        "x = torch.randn(2, 10, 128)  # batch=2, seq=10, dim=128\n",
        "weights, indices = router(x)\n",
        "\n",
        "print(f\"Routing weights shape: {weights.shape}\")\n",
        "print(f\"Expert indices shape: {indices.shape}\")\n",
        "print(f\"\\nFirst token routes to experts: {indices[0, 0].tolist()}\")\n",
        "print(f\"With weights: {weights[0, 0].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Output Folder Structure\n",
        "\n",
        "PacerKit creates a well-organized output folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example output structure:\n",
        "# merged_qwen_coder_20251209_205733/\n",
        "# ‚îú‚îÄ‚îÄ config.json              # Model config\n",
        "# ‚îú‚îÄ‚îÄ model.safetensors        # Model weights\n",
        "# ‚îú‚îÄ‚îÄ README.md                # Auto-generated model card\n",
        "# ‚îú‚îÄ‚îÄ merge_config.json        # PACER merge configuration\n",
        "# ‚îú‚îÄ‚îÄ merge_report.json        # Detailed merge decisions\n",
        "# ‚îî‚îÄ‚îÄ logs/                    # Log files (if any)\n",
        "\n",
        "import json\n",
        "\n",
        "# View merge report\n",
        "# with open(\"./merged_qwen_coder/merge_report.json\", \"r\") as f:\n",
        "#     report = json.load(f)\n",
        "#     print(json.dumps(report['summary'], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Advanced: Custom Merge Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pacerkit import PACERMerger, PACERConfig\n",
        "from pacerkit.config import PACERSettings, OutputConfig\n",
        "\n",
        "# Create custom config\n",
        "config = PACERConfig(\n",
        "    project_name=\"custom-merge\",\n",
        "    models=[\n",
        "        \"fluently/FluentlyQwen3-Coder-4B-0909\",\n",
        "        \"SamuelBang/AesCoder-4B\"\n",
        "    ],\n",
        "    pacer=PACERSettings(\n",
        "        interference_threshold=0.25,  # Lower = more MoE layers\n",
        "        top_k_experts=3,              # Activate 3 experts per token\n",
        "        dropout_rate=0.15,\n",
        "        expert_cluster_threshold=0.85,\n",
        "    ),\n",
        "    output=OutputConfig(\n",
        "        path=\"./custom_merged\",\n",
        "        add_timestamp=True,\n",
        "        push_to_hub=False,\n",
        "    )\n",
        ")\n",
        "\n",
        "# Run merge with custom config\n",
        "# merger = PACERMerger(config=config)\n",
        "# merged = merger.merge()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyzing Merge Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get detailed interference report\n",
        "# report = merger.get_interference_report()\n",
        "\n",
        "# Visualize interference distribution\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# scores = [score for _, (score, _) in report['layers'].items()]\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(scores, bins=50, edgecolor='black')\n",
        "# plt.axvline(x=0.35, color='r', linestyle='--', label='Threshold')\n",
        "# plt.xlabel('Interference Score')\n",
        "# plt.ylabel('Number of Layers')\n",
        "# plt.title('Distribution of Interference Scores')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Testing the Merged Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and test the merged model\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"./merged_qwen_coder\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"fluently/FluentlyQwen3-Coder-4B-0909\")\n",
        "\n",
        "# # Test generation\n",
        "# prompt = \"def fibonacci(n):\"\n",
        "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "# outputs = model.generate(**inputs, max_length=100)\n",
        "# print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Next Steps\n",
        "\n",
        "- Read the [methodology documentation](../docs/methodology.md) for full technical details\n",
        "- Explore different interference thresholds for your use case\n",
        "- Try merging Vision Transformers with Token Merging enabled\n",
        "- Share your merged models on HuggingFace Hub!\n",
        "\n",
        "## üîó Resources\n",
        "\n",
        "- [GitHub Repository](https://github.com/yourusername/pacerkit)\n",
        "- [Configuration Reference](../README.md#configuration)\n",
        "- [PACER Methodology](../docs/methodology.md)\n",
        "\n",
        "For questions and contributions, visit the GitHub repository!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
